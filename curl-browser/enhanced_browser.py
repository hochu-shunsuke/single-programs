#!/usr/bin/env python3
"""
Enhanced Terminal Browser with BeautifulSoup
ã‚ˆã‚Šé«˜æ©Ÿèƒ½ãªç°¡æ˜“ãƒ–ãƒ©ã‚¦ã‚¶ï¼ˆBeautifulSoupä½¿ç”¨ç‰ˆï¼‰

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
pip install beautifulsoup4 requests

ä½¿ç”¨æ–¹æ³•:
python enhanced_browser.py [URL]
"""

import subprocess
import sys
import os
import urllib.parse
from typing import Optional, List, Tuple, Dict

try:
    from bs4 import BeautifulSoup
    import requests
    ENHANCED_MODE = True
except ImportError:
    ENHANCED_MODE = False
    print("æ³¨æ„: beautifulsoup4ã¨requestsãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("åŸºæœ¬æ©Ÿèƒ½ã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚")
    print("pip install beautifulsoup4 requests ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚")

class EnhancedBrowser:
    def __init__(self):
        self.current_url = ""
        self.history = []
        self.history_index = -1
        self.bookmarks = []
        self.session = requests.Session() if ENHANCED_MODE else None
        
        if self.session:
            self.session.headers.update({
                'User-Agent': 'Enhanced-Terminal-Browser/1.0 (curl-based)'
            })
    
    def fetch_page_curl(self, url: str) -> Optional[str]:
        """curlã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã£ã¦Webãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            cmd = [
                'curl', '-s', '-L',
                '-H', 'User-Agent: Enhanced-Terminal-Browser/1.0',
                '-H', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                '--max-time', '30',
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                return result.stdout
            else:
                print(f"curl ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None
    
    def fetch_page_requests(self, url: str) -> Optional[str]:
        """requestsã‚’ä½¿ã£ã¦Webãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            return response.text
                
        except Exception as e:
            print(f"ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None
    
    def fetch_page(self, url: str) -> Optional[str]:
        """Webãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆrequestsãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ãã‚Œã‚’ä½¿ç”¨ã€ãã†ã§ãªã‘ã‚Œã°curlï¼‰"""
        if ENHANCED_MODE:
            content = self.fetch_page_requests(url)
        else:
            content = self.fetch_page_curl(url)
        
        if content:
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            self.current_url = url
            self.add_to_history(url)
        
        return content
    
    def add_to_history(self, url: str):
        """å±¥æ­´ã«è¿½åŠ """
        if self.history_index < len(self.history) - 1:
            self.history = self.history[:self.history_index + 1]
        
        if not self.history or self.history[-1] != url:
            self.history.append(url)
            self.history_index = len(self.history) - 1
    
    def go_back(self) -> Optional[str]:
        """æˆ»ã‚‹"""
        if self.history_index > 0:
            self.history_index -= 1
            url = self.history[self.history_index]
            return self.fetch_page(url)
        return None
    
    def go_forward(self) -> Optional[str]:
        """é€²ã‚€"""
        if self.history_index < len(self.history) - 1:
            self.history_index += 1
            url = self.history[self.history_index]
            return self.fetch_page(url)
        return None
    
    def parse_html_enhanced(self, html: str) -> Tuple[str, List[Tuple[str, str]], Dict]:
        """BeautifulSoupã‚’ä½¿ã£ã¦HTMLã‚’è§£æ"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # titleå–å¾—
        title = soup.title.string if soup.title else "ç„¡é¡Œ"
        
        # script, styleã‚¿ã‚°ã‚’é™¤å»
        for script in soup(["script", "style"]):
            script.decompose()
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’å–å¾—
        text_content = soup.get_text()
        
        # è¤‡æ•°ã®ç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
        lines = (line.strip() for line in text_content.splitlines())
        text_content = '\n'.join(line for line in lines if line)
        
        # ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        links = []
        for link in soup.find_all('a', href=True):
            href = link['href']
            link_text = link.get_text().strip()
            
            # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
            href = urllib.parse.urljoin(self.current_url, href)
            
            if link_text and href.startswith(('http://', 'https://')):
                links.append((href, link_text))
        
        # ãƒ¡ã‚¿æƒ…å ±
        meta_info = {
            'title': title,
            'description': '',
            'keywords': ''
        }
        
        # ãƒ¡ã‚¿ã‚¿ã‚°ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            meta_info['description'] = meta_desc.get('content', '')
        
        meta_keywords = soup.find('meta', attrs={'name': 'keywords'})
        if meta_keywords:
            meta_info['keywords'] = meta_keywords.get('content', '')
        
        return text_content, links, meta_info
    
    def parse_html_basic(self, html: str) -> Tuple[str, List[Tuple[str, str]], Dict]:
        """åŸºæœ¬çš„ãªHTMLãƒ‘ãƒ¼ã‚¹ï¼ˆæ­£è¦è¡¨ç¾ä½¿ç”¨ï¼‰"""
        import re
        
        # titleã‚’æŠ½å‡º
        title_match = re.search(r'<title[^>]*>(.*?)</title>', html, re.IGNORECASE | re.DOTALL)
        title = title_match.group(1) if title_match else "ç„¡é¡Œ"
        
        # script, styleã‚¿ã‚°ã‚’é™¤å»
        text = re.sub(r'<script[^>]*>.*?</script>', '', html, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<[^>]+>', '', text)
        
        # HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        text = text.replace('&amp;', '&')
        text = text.replace('&quot;', '"')
        text = text.replace('&#39;', "'")
        text = text.replace('&nbsp;', ' ')
        
        # è¤‡æ•°ã®ç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r' +', ' ', text)
        
        # ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        links = []
        pattern = r'<a[^>]*href=["\']([^"\']+)["\'][^>]*>(.*?)</a>'
        matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)
        
        for href, link_text in matches:
            href = urllib.parse.urljoin(self.current_url, href)
            link_text = re.sub(r'<[^>]+>', '', link_text).strip()
            if link_text and href.startswith(('http://', 'https://')):
                links.append((href, link_text))
        
        meta_info = {'title': title, 'description': '', 'keywords': ''}
        
        return text.strip(), links, meta_info
    
    def display_page(self, html: str):
        """ãƒšãƒ¼ã‚¸å†…å®¹ã‚’è¡¨ç¤º"""
        if ENHANCED_MODE:
            text_content, links, meta_info = self.parse_html_enhanced(html)
        else:
            text_content, links, meta_info = self.parse_html_basic(html)
        
        print("=" * 80)
        print(f"ğŸ“„ {meta_info['title']}")
        print(f"ğŸŒ {self.current_url}")
        if meta_info['description']:
            print(f"ğŸ“ {meta_info['description'][:100]}...")
        print("=" * 80)
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’è¡¨ç¤º
        if text_content:
            lines = text_content.split('\n')
            display_lines = []
            
            for line in lines[:150]:  # æœ€å¤§150è¡Œã¾ã§è¡¨ç¤º
                if len(line) > 120:
                    display_lines.append(line[:120] + "...")
                else:
                    display_lines.append(line)
            
            print('\n'.join(display_lines))
            
            if len(lines) > 150:
                print(f"\n... (å…¨{len(lines)}è¡Œä¸­{len(display_lines)}è¡Œã‚’è¡¨ç¤º)")
        
        print("\n" + "-" * 80)
        
        # ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
        if links:
            print("ğŸ”— ãƒªãƒ³ã‚¯:")
            for i, (url, text) in enumerate(links[:25]):  # æœ€å¤§25å€‹ã¾ã§è¡¨ç¤º
                print(f"  {i+1:2d}. {text[:70]}...")
                print(f"      -> {url}")
            if len(links) > 25:
                print(f"  ... ä»–{len(links)-25}å€‹ã®ãƒªãƒ³ã‚¯")
        
        print("-" * 80)
    
    def add_bookmark(self, url: str = "", title: str = ""):
        """ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ """
        url = url or self.current_url
        if url:
            if not title and ENHANCED_MODE:
                # ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                html = self.fetch_page(url)
                if html:
                    _, _, meta_info = self.parse_html_enhanced(html)
                    title = meta_info['title']
            
            title = title or url
            self.bookmarks.append((url, title))
            print(f"ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ ã—ã¾ã—ãŸ: {title}")
    
    def show_bookmarks(self):
        """ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ä¸€è¦§ã‚’è¡¨ç¤º"""
        if not self.bookmarks:
            print("ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        print("ğŸ“š ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯:")
        for i, (url, title) in enumerate(self.bookmarks):
            print(f"  {i+1:2d}. {title}")
            print(f"      -> {url}")
    
    def search(self, query: str):
        """Googleæ¤œç´¢ã‚’å®Ÿè¡Œ"""
        search_url = f"https://www.google.com/search?q={urllib.parse.quote(query)}"
        html = self.fetch_page(search_url)
        if html:
            self.display_page(html)
    
    def run(self, initial_url: str = ""):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å®Ÿè¡Œ"""
        print("ğŸŒ Enhanced Terminal Browser")
        if ENHANCED_MODE:
            print("âœ… BeautifulSoup4, requests ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        else:
            print("âš ï¸  åŸºæœ¬æ©Ÿèƒ½ã§å‹•ä½œä¸­ï¼ˆcurlãƒ™ãƒ¼ã‚¹ï¼‰")
        
        print()
        print("ã‚³ãƒãƒ³ãƒ‰:")
        print("  [URL]           - URLã‚’é–‹ã")
        print("  [æ•°å­—]          - ãƒªãƒ³ã‚¯ç•ªå·ã‚’é–‹ã")
        print("  back            - æˆ»ã‚‹")
        print("  forward         - é€²ã‚€")
        print("  history         - å±¥æ­´è¡¨ç¤º")
        print("  bookmark        - ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ ")
        print("  bookmarks       - ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ä¸€è¦§")
        print("  search [ã‚¯ã‚¨ãƒª]  - Googleæ¤œç´¢")
        print("  help            - ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
        print("  quit            - çµ‚äº†")
        print("=" * 80)
        
        if initial_url:
            html = self.fetch_page(initial_url)
            if html:
                self.display_page(html)
        
        while True:
            try:
                command = input("\nğŸŒ > ").strip()
                
                if not command:
                    continue
                
                if command.lower() in ['quit', 'exit', 'q']:
                    print("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                elif command.lower() == 'help':
                    print("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:")
                    print("  URLå…¥åŠ›ã€backã€forwardã€historyã€bookmarkã€bookmarksã€searchã€quit")
                
                elif command.lower() == 'back':
                    html = self.go_back()
                    if html:
                        self.display_page(html)
                    else:
                        print("æˆ»ã‚‹ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                
                elif command.lower() == 'forward':
                    html = self.go_forward()
                    if html:
                        self.display_page(html)
                    else:
                        print("é€²ã‚€ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                
                elif command.lower() == 'history':
                    print("ğŸ“š å±¥æ­´:")
                    for i, url in enumerate(self.history):
                        marker = " ğŸ‘‰ " if i == self.history_index else "    "
                        print(f"{marker}{i+1}. {url}")
                
                elif command.lower() == 'bookmark':
                    self.add_bookmark()
                
                elif command.lower() == 'bookmarks':
                    self.show_bookmarks()
                
                elif command.lower().startswith('search '):
                    query = command[7:].strip()
                    if query:
                        print(f"ğŸ” Googleæ¤œç´¢: {query}")
                        self.search(query)
                    else:
                        print("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                
                elif command.isdigit():
                    # æ•°å­—ã®å ´åˆã¯ãƒªãƒ³ã‚¯ç•ªå·ã¨ã—ã¦å‡¦ç†
                    if self.current_url:
                        html_content = self.fetch_page(self.current_url)
                        if html_content:
                            if ENHANCED_MODE:
                                _, links, _ = self.parse_html_enhanced(html_content)
                            else:
                                _, links, _ = self.parse_html_basic(html_content)
                            
                            link_num = int(command) - 1
                            if 0 <= link_num < len(links):
                                url = links[link_num][0]
                                print(f"ğŸ”— ãƒªãƒ³ã‚¯ã‚’é–‹ã„ã¦ã„ã¾ã™: {url}")
                                html = self.fetch_page(url)
                                if html:
                                    self.display_page(html)
                            else:
                                print("ç„¡åŠ¹ãªãƒªãƒ³ã‚¯ç•ªå·ã§ã™ã€‚")
                    else:
                        print("ã¾ãšãƒšãƒ¼ã‚¸ã‚’é–‹ã„ã¦ãã ã•ã„ã€‚")
                
                else:
                    # URLã¨ã—ã¦å‡¦ç†
                    print(f"ğŸŒ ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ä¸­: {command}")
                    html = self.fetch_page(command)
                    if html:
                        self.display_page(html)
                
            except KeyboardInterrupt:
                print("\n\nãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def main():
    browser = EnhancedBrowser()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§URLãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    initial_url = sys.argv[1] if len(sys.argv) > 1 else ""
    
    browser.run(initial_url)

if __name__ == "__main__":
    main()
