#!/usr/bin/env python3
"""
Terminal Simple Browser
curlã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã£ãŸç°¡æ˜“ãƒ–ãƒ©ã‚¦ã‚¶

ä½¿ç”¨æ–¹æ³•:
python simple_browser.py [URL]
ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œå¾Œã«URLã‚’å…¥åŠ›
"""

import subprocess
import sys
import re
import urllib.parse
from typing import Optional, List, Tuple

class SimpleBrowser:
    def __init__(self):
        self.current_url = ""
        self.history = []
        self.history_index = -1
        
    def fetch_page(self, url: str) -> Optional[str]:
        """curlã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã£ã¦Webãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            # URLã®æ­£è¦åŒ–
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            # curlã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
            cmd = [
                'curl', '-s', '-L',  # -s: silent, -L: follow redirects
                '-H', 'User-Agent: Simple-Terminal-Browser/1.0',
                '-H', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                '--max-time', '30',  # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                self.current_url = url
                self.add_to_history(url)
                return result.stdout
            else:
                print(f"ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None
    
    def add_to_history(self, url: str):
        """å±¥æ­´ã«è¿½åŠ """
        if self.history_index < len(self.history) - 1:
            # å±¥æ­´ã®é€”ä¸­ã‹ã‚‰æ–°ã—ã„ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ãŸå ´åˆã€ãã‚Œä»¥é™ã®å±¥æ­´ã‚’å‰Šé™¤
            self.history = self.history[:self.history_index + 1]
        
        self.history.append(url)
        self.history_index = len(self.history) - 1
    
    def go_back(self) -> Optional[str]:
        """æˆ»ã‚‹"""
        if self.history_index > 0:
            self.history_index -= 1
            url = self.history[self.history_index]
            return self.fetch_page(url)
        return None
    
    def go_forward(self) -> Optional[str]:
        """é€²ã‚€"""
        if self.history_index < len(self.history) - 1:
            self.history_index += 1
            url = self.history[self.history_index]
            return self.fetch_page(url)
        return None
    
    def parse_html(self, html: str) -> str:
        """HTMLã‚’è§£æã—ã¦èª­ã¿ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        if not html:
            return ""
        
        # HTMLã‚¿ã‚°ã‚’é™¤å»ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        text = re.sub(r'<script[^>]*>.*?</script>', '', html, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<[^>]+>', '', text)
        
        # HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        text = text.replace('&amp;', '&')
        text = text.replace('&quot;', '"')
        text = text.replace('&#39;', "'")
        text = text.replace('&nbsp;', ' ')
        
        # è¤‡æ•°ã®ç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r' +', ' ', text)
        
        return text.strip()
    
    def extract_links(self, html: str) -> List[Tuple[str, str]]:
        """HTMLã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º"""
        links = []
        # aã‚¿ã‚°ã®hrefå±æ€§ã‚’æŠ½å‡º
        pattern = r'<a[^>]*href=["\']([^"\']+)["\'][^>]*>(.*?)</a>'
        matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)
        
        for href, text in matches:
            # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
            if href.startswith('/'):
                base_url = urllib.parse.urlparse(self.current_url)
                href = f"{base_url.scheme}://{base_url.netloc}{href}"
            elif not href.startswith(('http://', 'https://')):
                href = urllib.parse.urljoin(self.current_url, href)
            
            # ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰HTMLã‚¿ã‚°ã‚’é™¤å»
            link_text = re.sub(r'<[^>]+>', '', text).strip()
            if link_text:
                links.append((href, link_text))
        
        return links
    
    def display_page(self, html: str):
        """ãƒšãƒ¼ã‚¸å†…å®¹ã‚’è¡¨ç¤º"""
        print("=" * 80)
        print(f"URL: {self.current_url}")
        print("=" * 80)
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’è¡¨ç¤º
        text_content = self.parse_html(html)
        if text_content:
            # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­éƒ¨åˆ†ã®ã¿è¡¨ç¤º
            lines = text_content.split('\n')
            if len(lines) > 100:
                lines = lines[:100]
                print('\n'.join(lines))
                print(f"\n... ({len(text_content.split())} è¡Œã®å†…å®¹ãŒã‚ã‚Šã¾ã™)")
            else:
                print(text_content)
        
        print("\n" + "-" * 80)
        
        # ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
        links = self.extract_links(html)
        if links:
            print("ãƒªãƒ³ã‚¯:")
            for i, (url, text) in enumerate(links[:20]):  # æœ€å¤§20å€‹ã¾ã§è¡¨ç¤º
                print(f"  {i+1:2d}. {text[:60]}... -> {url}")
            if len(links) > 20:
                print(f"  ... ä»–{len(links)-20}å€‹ã®ãƒªãƒ³ã‚¯")
        
        print("-" * 80)
    
    def run(self, initial_url: str = ""):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å®Ÿè¡Œ"""
        print("ğŸŒ Simple Terminal Browser")
        print("ã‚³ãƒãƒ³ãƒ‰: [URL], back, forward, links, history, quit")
        print("=" * 80)
        
        if initial_url:
            html = self.fetch_page(initial_url)
            if html:
                self.display_page(html)
        
        while True:
            try:
                command = input("\n> ").strip()
                
                if not command:
                    continue
                
                if command.lower() in ['quit', 'exit', 'q']:
                    print("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                elif command.lower() == 'back':
                    html = self.go_back()
                    if html:
                        self.display_page(html)
                    else:
                        print("æˆ»ã‚‹ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                
                elif command.lower() == 'forward':
                    html = self.go_forward()
                    if html:
                        self.display_page(html)
                    else:
                        print("é€²ã‚€ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                
                elif command.lower() == 'history':
                    print("å±¥æ­´:")
                    for i, url in enumerate(self.history):
                        marker = " -> " if i == self.history_index else "    "
                        print(f"{marker}{i+1}. {url}")
                
                elif command.lower() == 'links':
                    if self.current_url:
                        html = self.fetch_page(self.current_url)
                        if html:
                            links = self.extract_links(html)
                            if links:
                                print("åˆ©ç”¨å¯èƒ½ãªãƒªãƒ³ã‚¯:")
                                for i, (url, text) in enumerate(links):
                                    print(f"  {i+1:2d}. {text} -> {url}")
                            else:
                                print("ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        print("ã¾ãšãƒšãƒ¼ã‚¸ã‚’é–‹ã„ã¦ãã ã•ã„ã€‚")
                
                elif command.isdigit():
                    # æ•°å­—ã®å ´åˆã¯ãƒªãƒ³ã‚¯ç•ªå·ã¨ã—ã¦å‡¦ç†
                    if self.current_url:
                        html_content = self.fetch_page(self.current_url)
                        if html_content:
                            links = self.extract_links(html_content)
                            link_num = int(command) - 1
                            if 0 <= link_num < len(links):
                                url = links[link_num][0]
                                html = self.fetch_page(url)
                                if html:
                                    self.display_page(html)
                            else:
                                print("ç„¡åŠ¹ãªãƒªãƒ³ã‚¯ç•ªå·ã§ã™ã€‚")
                    else:
                        print("ã¾ãšãƒšãƒ¼ã‚¸ã‚’é–‹ã„ã¦ãã ã•ã„ã€‚")
                
                else:
                    # URLã¨ã—ã¦å‡¦ç†
                    html = self.fetch_page(command)
                    if html:
                        self.display_page(html)
                
            except KeyboardInterrupt:
                print("\n\nãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def main():
    browser = SimpleBrowser()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§URLãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    initial_url = sys.argv[1] if len(sys.argv) > 1 else ""
    
    browser.run(initial_url)

if __name__ == "__main__":
    main()
